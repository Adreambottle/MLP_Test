{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1\n",
    "\n",
    "* Author: Yanan ZHOU\n",
    "\n",
    "* Contact: adreambottle@outlook.com\n",
    "\n",
    "* Topic: Portfolio Construction Method - Thought of Maximum Sharpe Ratio in Combining Different Alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "We define alpha as a trading strategy, which can also be considered as a factor, or a feature.\n",
    "\n",
    "Itâ€™s just that this feature, represented by f, represents the forecast of stock returns, and it has some predictive ability, that is, IC = corr(f, r) > 0\n",
    "\n",
    "Generally speaking, every trading firm will accumulate a lot of such alpha.\n",
    "\n",
    "Suppose we have N alphas, which means we have N different strategies\n",
    "\n",
    "Different alphas may make money in different aspects, for example, some are making money from the reversal effect, and some are making money from the momentum effect. How to combine these alphas to make the final generated signal have stronger and more stable predictive power.\n",
    "\n",
    "This is often a classic regression task in machine learning, i.e. constructing a r_pred = f(a1 + a2 ... aN)\n",
    "\n",
    "But here I adopt the idea of maximize sharpe ratio to build the alpha combo which is the strongest signal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Maximize Sharpe Ratio on different alphas\n",
    "\n",
    "In the classic Markowitz model, we need to calculate the mean and the correlation for each stock. \n",
    "\n",
    "But here we choose to switch dimensions. When we have many strategies, we can calculate the expected return and the covariance matrix of different alphas.\n",
    "\n",
    "Of course, there are some areas that need modification and attention. For example, when calculating the covariance matrix, how to choose the correct time window, how to make corrections based on the difference between the short term and the long term, and the alpha information generally decays over time, and how to punish the attenuation coefficient.\n",
    "\n",
    "\n",
    "We can first trade each alpha separately to get their performance on historical backtests.\n",
    "\n",
    "In this way, we can get a DataFrame. The index of the DataFrame is the trading day, and the columns are each factor. Each item in it is the pnl of a day when a factor is traded alone.\n",
    "\n",
    "Then record the historical backtest situation of this alpha to calculate the expected return and historical covariance matrix of each alphas.\n",
    "\n",
    "Then we can perform Maximum Sharpe Ratio Optimization based on the expected rate of return r and the covariance matrix Sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import bisect\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "import mosek.fusion as mf\n",
    "\n",
    "import tushare as ts\n",
    "token = \"xxxxxxxxxxxxxxxxxxxxxx\"\n",
    "ts.set_token(token)\n",
    "pro = ts.pro_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions Needed\n",
    "\n",
    "def set_random_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def get_datelist(start: str, end: str, interval: int):\n",
    "    df = pro.index_daily(ts_code='399300.SZ', start_date=start, end_date=end)\n",
    "    date_list = list(df.iloc[::-1]['trade_date'])\n",
    "    sample_list = []\n",
    "    for i in range(len(date_list)):\n",
    "        if i % interval == 0:\n",
    "            sample_list.append(date_list[i])\n",
    "\n",
    "    return sample_list\n",
    "\n",
    "def sharpe_func(wts, r, Sigma, decay_ratio):\n",
    "    if decay_ratio is not None:\n",
    "        assert len(r) == len(decay_ratio)\n",
    "        r = r * decay_ratio\n",
    "    fracNumer = r @ wts\n",
    "    fracDenom = np.sqrt(wts @ Sigma @ wts.T)\n",
    "    sharpe = fracNumer / fracDenom\n",
    "    return sharpe\n",
    "\n",
    "def revalue_ignore_minimal(x, epsilon=1e-6):\n",
    "    valid_ = x > epsilon\n",
    "    x_v = x[valid_]\n",
    "    x_v = x_v / x_v.sum()\n",
    "    x_new = np.zeros(x.shape)\n",
    "    x_new[valid_] = x_v\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20210104' '20210105' '20210106' '20210107' '20210108' '20210111'\n",
      " '20210112' '20210113' '20210114' '20210115']\n",
      "DatetimeIndex(['2021-01-04', '2021-01-05', '2021-01-06', '2021-01-07',\n",
      "               '2021-01-08', '2021-01-11', '2021-01-12', '2021-01-13',\n",
      "               '2021-01-14', '2021-01-15'],\n",
      "              dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Generate pseudo data\n",
    "\n",
    "set_random_seed()\n",
    "\n",
    "sta_date = \"20210101\"\n",
    "end_date = \"20230101\"\n",
    "pred_sta_date = \"20220101\"\n",
    "\n",
    "dates_str = np.array(get_datelist(sta_date, end_date, interval=1))\n",
    "pred_dates_str = dates_str[dates_str >= pred_sta_date]\n",
    "dates_dt = pd.to_datetime(dates_str)\n",
    "\n",
    "print(dates_str[:10])\n",
    "print(dates_dt[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sc/s_x4ss8x4lg2_cd9vrpn5ty80000gn/T/ipykernel_21170/2133621154.py:16: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "  df_pnl = np.random.multivariate_normal(alpha_mean, alpha_cov, nDays)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha.1</th>\n",
       "      <th>alpha.2</th>\n",
       "      <th>alpha.3</th>\n",
       "      <th>alpha.4</th>\n",
       "      <th>alpha.5</th>\n",
       "      <th>alpha.6</th>\n",
       "      <th>alpha.7</th>\n",
       "      <th>alpha.8</th>\n",
       "      <th>alpha.9</th>\n",
       "      <th>alpha.10</th>\n",
       "      <th>alpha.11</th>\n",
       "      <th>alpha.12</th>\n",
       "      <th>alpha.13</th>\n",
       "      <th>alpha.14</th>\n",
       "      <th>alpha.15</th>\n",
       "      <th>alpha.16</th>\n",
       "      <th>alpha.17</th>\n",
       "      <th>alpha.18</th>\n",
       "      <th>alpha.19</th>\n",
       "      <th>alpha.20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20210104</th>\n",
       "      <td>0.175507</td>\n",
       "      <td>0.108104</td>\n",
       "      <td>0.097669</td>\n",
       "      <td>0.064396</td>\n",
       "      <td>-0.149448</td>\n",
       "      <td>0.095731</td>\n",
       "      <td>0.232076</td>\n",
       "      <td>0.075986</td>\n",
       "      <td>0.195391</td>\n",
       "      <td>-0.008511</td>\n",
       "      <td>0.040260</td>\n",
       "      <td>0.212479</td>\n",
       "      <td>0.081840</td>\n",
       "      <td>-0.103904</td>\n",
       "      <td>-0.037957</td>\n",
       "      <td>-0.041939</td>\n",
       "      <td>0.171815</td>\n",
       "      <td>0.078638</td>\n",
       "      <td>-0.062942</td>\n",
       "      <td>0.067815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210105</th>\n",
       "      <td>-0.197140</td>\n",
       "      <td>0.105874</td>\n",
       "      <td>0.037805</td>\n",
       "      <td>0.126539</td>\n",
       "      <td>-0.100943</td>\n",
       "      <td>0.120614</td>\n",
       "      <td>0.096266</td>\n",
       "      <td>0.143533</td>\n",
       "      <td>0.079840</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>-0.024879</td>\n",
       "      <td>0.007868</td>\n",
       "      <td>-0.051814</td>\n",
       "      <td>0.141464</td>\n",
       "      <td>-0.187917</td>\n",
       "      <td>-0.125777</td>\n",
       "      <td>0.057235</td>\n",
       "      <td>0.205519</td>\n",
       "      <td>0.015436</td>\n",
       "      <td>-0.053104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210106</th>\n",
       "      <td>-0.357126</td>\n",
       "      <td>0.140206</td>\n",
       "      <td>-0.026876</td>\n",
       "      <td>-0.019866</td>\n",
       "      <td>0.066149</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>-0.119102</td>\n",
       "      <td>-0.067050</td>\n",
       "      <td>-0.152019</td>\n",
       "      <td>-0.158415</td>\n",
       "      <td>0.080985</td>\n",
       "      <td>-0.035537</td>\n",
       "      <td>-0.079961</td>\n",
       "      <td>-0.114369</td>\n",
       "      <td>0.064091</td>\n",
       "      <td>0.105191</td>\n",
       "      <td>-0.072333</td>\n",
       "      <td>0.089578</td>\n",
       "      <td>-0.042756</td>\n",
       "      <td>-0.055685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210107</th>\n",
       "      <td>0.018244</td>\n",
       "      <td>0.120214</td>\n",
       "      <td>-0.045615</td>\n",
       "      <td>0.011167</td>\n",
       "      <td>-0.001188</td>\n",
       "      <td>0.263233</td>\n",
       "      <td>-0.064086</td>\n",
       "      <td>0.196544</td>\n",
       "      <td>0.090425</td>\n",
       "      <td>0.159310</td>\n",
       "      <td>0.122886</td>\n",
       "      <td>0.198280</td>\n",
       "      <td>0.113785</td>\n",
       "      <td>0.022714</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>-0.086065</td>\n",
       "      <td>0.070379</td>\n",
       "      <td>-0.083138</td>\n",
       "      <td>0.104075</td>\n",
       "      <td>-0.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210108</th>\n",
       "      <td>-0.028989</td>\n",
       "      <td>0.211263</td>\n",
       "      <td>0.076148</td>\n",
       "      <td>0.122874</td>\n",
       "      <td>0.167597</td>\n",
       "      <td>0.263187</td>\n",
       "      <td>-0.147169</td>\n",
       "      <td>0.299415</td>\n",
       "      <td>-0.013955</td>\n",
       "      <td>0.047909</td>\n",
       "      <td>-0.202903</td>\n",
       "      <td>0.132695</td>\n",
       "      <td>-0.163651</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>-0.101159</td>\n",
       "      <td>0.205360</td>\n",
       "      <td>-0.110574</td>\n",
       "      <td>-0.096554</td>\n",
       "      <td>0.088282</td>\n",
       "      <td>-0.098233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           alpha.1   alpha.2   alpha.3   alpha.4   alpha.5   alpha.6  \\\n",
       "20210104  0.175507  0.108104  0.097669  0.064396 -0.149448  0.095731   \n",
       "20210105 -0.197140  0.105874  0.037805  0.126539 -0.100943  0.120614   \n",
       "20210106 -0.357126  0.140206 -0.026876 -0.019866  0.066149  0.074192   \n",
       "20210107  0.018244  0.120214 -0.045615  0.011167 -0.001188  0.263233   \n",
       "20210108 -0.028989  0.211263  0.076148  0.122874  0.167597  0.263187   \n",
       "\n",
       "           alpha.7   alpha.8   alpha.9  alpha.10  alpha.11  alpha.12  \\\n",
       "20210104  0.232076  0.075986  0.195391 -0.008511  0.040260  0.212479   \n",
       "20210105  0.096266  0.143533  0.079840  0.003582 -0.024879  0.007868   \n",
       "20210106 -0.119102 -0.067050 -0.152019 -0.158415  0.080985 -0.035537   \n",
       "20210107 -0.064086  0.196544  0.090425  0.159310  0.122886  0.198280   \n",
       "20210108 -0.147169  0.299415 -0.013955  0.047909 -0.202903  0.132695   \n",
       "\n",
       "          alpha.13  alpha.14  alpha.15  alpha.16  alpha.17  alpha.18  \\\n",
       "20210104  0.081840 -0.103904 -0.037957 -0.041939  0.171815  0.078638   \n",
       "20210105 -0.051814  0.141464 -0.187917 -0.125777  0.057235  0.205519   \n",
       "20210106 -0.079961 -0.114369  0.064091  0.105191 -0.072333  0.089578   \n",
       "20210107  0.113785  0.022714  0.180259 -0.086065  0.070379 -0.083138   \n",
       "20210108 -0.163651  0.002918 -0.101159  0.205360 -0.110574 -0.096554   \n",
       "\n",
       "          alpha.19  alpha.20  \n",
       "20210104 -0.062942  0.067815  \n",
       "20210105  0.015436 -0.053104  \n",
       "20210106 -0.042756 -0.055685  \n",
       "20210107  0.104075 -0.122200  \n",
       "20210108  0.088282 -0.098233  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nDays = len(dates_dt)\n",
    "nAlpha = 20\n",
    "nStock = 3000\n",
    "alpha_mean = np.random.rand(nAlpha) / 20\n",
    "alpha_corr = np.random.rand(nAlpha, nAlpha) - 0.5\n",
    "for i in range(nAlpha):\n",
    "    for j in range(nAlpha):\n",
    "        if i < j:\n",
    "            alpha_corr[i, j] = alpha_corr[j, i]\n",
    "        elif i == j:\n",
    "            alpha_corr[i, j] = 1.\n",
    "\n",
    "decay_ratio = 1 - np.random.rand(nAlpha) * 0.5\n",
    "\n",
    "alpha_cov = alpha_corr / 100.\n",
    "df_pnl = np.random.multivariate_normal(alpha_mean, alpha_cov, nDays)\n",
    "alpha_names = [f\"alpha.{i}\" for i in range(1, nAlpha+1)]\n",
    "\n",
    "\n",
    "df_pnl = pd.DataFrame(df_pnl, index=dates_str, columns=alpha_names)\n",
    "df_pnl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because Sharpe Ratio optimization is a fractional optimization problem, not an easy-to-solve convex optimization problem, here I give two solutions, one is to use MOSEK to perform Schaible transform to solve a specific Fraction Optimize Problem, and the other is to use Sequential Least Squares Programming optimize (SLSQP) to solve more general situations, that is, several variables with any combination of bounds, equality and inequality constraints\n",
    "\n",
    "\n",
    "Solve for the optimal investment portfolio. The weight x maximizes the Sharpe Ratio of the investment portfolio.\n",
    "\n",
    "$max_{x} \\quad \\cfrac{r^Tx - r_f}{||Fx||_2} \\\\ s.t. \\quad 1^Tx=1, \\\\ \\quad x \\ge 0$â€‹\n",
    "\n",
    "$x$ is the vector of asset allocations\n",
    "\n",
    "$F$ is risk associated with the covariance matrix $||Fx||_2 = \\sqrt{x^T\\Sigma x}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Because this is fractional programming (FP), and because the numerator is greater than or equal to 0, it is concave, and the denominator greater than 0 is convex. So we can consider concave-convex single-ratio FP\n",
    "\n",
    "We use the form of Schaible transform to solve\n",
    "\n",
    "We can set some new variables $w = \\cfrac{x}{ \\sqrt{x^T\\Sigma x}}, \\quad t = \\cfrac{1}{ \\sqrt{x^T\\Sigma x}}, \\quad w = \\cfrac{x}{t}$â€‹\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The original maximum Sharpe ratio is equivalent to the convex quadratic problem (QP)\n",
    "\n",
    "$$max_{x} \\quad r^Tw -r_ft \\\\ s.t. \\quad w^T\\Sigma w \\leq 1, \\\\ \\qquad 1^T w \\geq 0,\\\\ \\qquad w \\geq 0$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then we can eliminate redundant variables t\n",
    "\n",
    "$$max_{x} \\quad w^T(r-r_f\\cdot 1) \\\\ s.t. \\quad w^T\\Sigma w \\leq 1, \\\\ \\qquad 1^T w \\geq 0,\\\\ \\qquad w \\geq 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then convert the QP problem to minimize $\\sqrt{w^T\\Sigma w}$ term\n",
    "\n",
    "$$min_{x} \\quad w^T\\Sigma w \\\\ s.t. \\quad w^T(r-r_f\\cdot 1)=1, \\\\ \\qquad 1^T w \\geq 0,\\\\ \\qquad w \\geq 0$$\n",
    "\n",
    "In this way, the value of Maximize Sharpe Ratio can be obtained very quickly by solving QP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxSharpe():\n",
    "\n",
    "    def __init__(self, r, Sigma, rf, decay_ratio=None, method=\"MOSEK\", tolerance=1e-8):\n",
    "        \"\"\"\n",
    "        r = np.mean(df_pnl, axis=0) # mean return of all alphas\n",
    "        rf = 0. # risk free interest rate\n",
    "        Sigma = np.cov(df_pnl, rowvar=False) # covariance of returns of all alphas\n",
    "        \"\"\"\n",
    "        self.r = r\n",
    "        self.rf = rf\n",
    "        self.Sigma = Sigma\n",
    "        self.tolerance = tolerance\n",
    "        self.nAlpha = len(r)\n",
    "        self.method = method.lower()\n",
    "\n",
    "    def solve(self):\n",
    "        if self.method == \"mosek\":\n",
    "            print(\"Call MOSEK to solve the problem\")\n",
    "            r = self.r + 1.\n",
    "            rf = self.rf + 1.\n",
    "            Sigma = self.Sigma\n",
    "            if not self.is_pos_def(Sigma):\n",
    "                II = np.eye(self.nAlpha) * 1e-10\n",
    "                Sigma = Sigma + II\n",
    "            L_matrix = np.linalg.cholesky(Sigma)\n",
    "            F = L_matrix.T\n",
    "\n",
    "            try:\n",
    "                wts = self.MaxSharpeMosek(r, rf, F, full=True, pos=True)\n",
    "            except:\n",
    "                print(\"MOSEK Fails, using SLSQP method\")\n",
    "                r = self.r\n",
    "                rf = self.rf\n",
    "                Sigma = self.Sigma\n",
    "                tolerance = self.tolerance\n",
    "                wts = self.MaxSharpeSLSQP(r, rf, Sigma, tolerance)\n",
    "\n",
    "        if self.method == \"slsqp\":\n",
    "            r = self.r\n",
    "            rf = self.rf\n",
    "            Sigma = self.Sigma\n",
    "            tolerance = self.tolerance\n",
    "            wts = self.MaxSharpeSLSQP(r, rf, Sigma, tolerance)\n",
    "\n",
    "        return wts\n",
    "    \n",
    "    def MaxSharpeMosek(self, r, rf, F, full=True, pos=True):\n",
    "        with mf.Model(\"Sharpe\") as M:\n",
    "            n = self.nAlpha\n",
    "            y = M.variable(\"y\", n. mf.Domain.greaterThan(0) if pos else mf.Domain.unbounded())\n",
    "            z = M.variable(\"z\", mf.Domain.greaterThan(0))\n",
    "\n",
    "            t = M.variable()\n",
    "            M.constraint(mf.Expr.vstack(t, mf.Expr.mul(F, y)), mf.Domain.inQCone())\n",
    "            M.objective(mf.ObjectiveSense.Minimize, t)\n",
    "\n",
    "            M.constraint(mf.Expr.sub(mf.Expr.dot(r, y), mf.Expr.mul(rf, z)), mf.Domain.equalsTo(1))\n",
    "\n",
    "            if full:\n",
    "                M.constraint(mf.Expr.sub(mf.Expr.sum(y), z), mf.Domain.equalsTo(0))\n",
    "\n",
    "            M.solve()\n",
    "\n",
    "            if M.getProblemStatus() == mf.ProblemStatus.PrimalAndDualFeasible and z.level()[0] > 0:\n",
    "                zval = z.level()[0]\n",
    "                return np.array([yi/zval for yi in y.level()])\n",
    "            else:\n",
    "                raise ValueError(\"No Solution or some issue\")\n",
    "\n",
    "\n",
    "    def MaxSharpeSLSQP(self, r, rf, Sigma, tolerance=1e-7):\n",
    "        \n",
    "        def neg_sharpe_func(x, r, Sigma, rf):\n",
    "            fracNumer = r @ x.T - rf\n",
    "            fracDenom = np.sqrt(x @ Sigma @ x.T)\n",
    "            sharpe = fracNumer / fracDenom\n",
    "            return -sharpe\n",
    "\n",
    "        def constraintEq(x):\n",
    "            A = np.ones(x.shape)\n",
    "            b = 1\n",
    "            constraintVal = np.matmul(A, x.T) - b\n",
    "            return constraintVal\n",
    "        \n",
    "        nAlpha = self.nAlpha\n",
    "        x_init = np.repeat(1/nAlpha, nAlpha)\n",
    "        constraints = ({\"type\" : \"eq\", \"fun\":constraintEq})\n",
    "        lb = 0.\n",
    "        ub = 1.\n",
    "        bounds = tuple([(lb, ub) for xi in x_init])\n",
    "\n",
    "        opt = optimize.minimize(\n",
    "            neg_sharpe_func,\n",
    "            x0 = x_init,\n",
    "            args = (r, Sigma, rf, nAlpha),\n",
    "            method = \"SLSQP\",\n",
    "            bounds = bounds,\n",
    "            constraints = constraints,\n",
    "            tol = tolerance\n",
    "        )\n",
    "        wts = opt.x\n",
    "        return wts\n",
    "\n",
    "\n",
    "def get_datelist(start: str, end: str, interval: int):\n",
    "    df = pro.index_daily(ts_code='399300.SZ', start_date=start, end_date=end)\n",
    "    date_list = list(df.iloc[::-1]['trade_date'])\n",
    "    sample_list = []\n",
    "    for i in range(len(date_list)):\n",
    "        if i % interval == 0:\n",
    "            sample_list.append(date_list[i])\n",
    "\n",
    "    return sample_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Code\n",
    "\n",
    "Here are the full codes of this problem, for more see the \"max_sharpe.py\" filw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    sta_date = \"20210101\"\n",
    "    end_date = \"20230101\"\n",
    "    pred_sta_date = \"20220101\"\n",
    "    \n",
    "    dates_str = np.array(get_datelist(sta_date, end_date, interval=1))\n",
    "    pred_dates_str = dates_str[dates_str >= pred_sta_date]\n",
    "    dates_dt = pd.to_datetime(dates_str)\n",
    "    \n",
    "    nDays = len(dates_dt)\n",
    "\n",
    "    nAlpha = 20\n",
    "    nStock = 3000\n",
    "    alpha_mean = np.random.rand(nAlpha) / 20\n",
    "    alpha_corr = np.random.rand(nAlpha, nAlpha) - 0.5\n",
    "    for i in range(nAlpha):\n",
    "        for j in range(nAlpha):\n",
    "            if i < j:\n",
    "                alpha_corr[i, j] = alpha_corr[j, i]\n",
    "            elif i == j:\n",
    "                alpha_corr[i, j] = 1.\n",
    "    \n",
    "    decay_ratio = 1 - np.random.rand(nAlpha) * 0.5\n",
    "\n",
    "    alpha_cov = alpha_corr / 100.\n",
    "    df_pnl = np.random.multivariate_normal(alpha_mean, alpha_cov, nDays)\n",
    "    alpha_names = [f\"alpha.{i}\" for i in range(1, nAlpha+1)]\n",
    "    \n",
    "\n",
    "    df_pnl = pd.DataFrame(df_pnl, index=dates_str, columns=alpha_names)\n",
    "    \n",
    "    rf = 0.03 / 365\n",
    "    rolling = False\n",
    "    rolling_window = 180\n",
    "    mean_decay = True\n",
    "    cov_decay = False\n",
    "\n",
    "    wts_list = []\n",
    "    for tidx, today in tqdm(enumerate(pred_dates_str)):\n",
    "        if rolling:\n",
    "            train_index = dates_str[dates_str < today]\n",
    "            train_len = len(train_index)\n",
    "        else:\n",
    "            train_index = dates_str[dates_str < today]\n",
    "            train_len = len(train_index)\n",
    "            \n",
    "            train_index = train_index[train_len-rolling_window:train_len]\n",
    "        \n",
    "        df_pnl_sep = df_pnl.loc[train_index, :]\n",
    "        decay_ratio = np.repeat(decay_ratio, train_len).reshape(nAlpha, -1).T\n",
    "        df_pnl_sep_decay = df_pnl_sep * decay_ratio\n",
    "        if mean_decay:\n",
    "            r = df_pnl_sep_decay.means().values\n",
    "        else:\n",
    "            r = df_pnl_sep.means().values\n",
    "        \n",
    "        if cov_decay:\n",
    "            Sigma = df_pnl_sep_decay.cov().values\n",
    "        else:\n",
    "            Sigma = df_pnl_sep.cov().values\n",
    "\n",
    "        wts = MaxSharpe(r, Sigma, rf=rf, method=\"MOSEK\").solve()\n",
    "        wts_list.append(wts)\n",
    "\n",
    "        fcst = np.random.randn(nStock, nAlpha)\n",
    "        fcst = pd.DataFrame(fcst, columns=alpha_names)\n",
    "        combo_fcst = fcst @ wts \n",
    "        combo_fcst.to_csv(f\"{today}_combo_fcst.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
